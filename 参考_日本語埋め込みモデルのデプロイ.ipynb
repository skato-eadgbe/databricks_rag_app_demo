{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc4ff827-f702-4fcd-9364-705bf9cb8f0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Databricks RAGアプリチュートリアル - 参考: 日本語埋め込みモデルのデプロイ\n",
    "\n",
    "このノートブックでは、日本語対応の埋め込みモデル[pfnet/plamo-embedding-1b](https://huggingface.co/pfnet/plamo-embedding-1b)をDatabricks上でMLflow登録からモデルサービングエンドポイントの作成まで、一連のデプロイフローを実行します。\n",
    "\n",
    "## このノートブックで学習する内容\n",
    "1. **Hugging Face モデルの取得**とローカルでの動作確認\n",
    "2. **MLflowモデル登録**：`sentence_transformers`フレーバーでの登録方法\n",
    "3. **Unity Catalogモデル管理**：企業レベルのモデルガバナンス\n",
    "4. **モデルサービングエンドポイント作成**：本番利用可能なAPI提供\n",
    "5. **エンドポイントテスト**：デプロイしたモデルの動作確認\n",
    "\n",
    "## 前提条件\n",
    "\n",
    "ワークショップ共通の動作条件はREADME.mdをご確認ください。\n",
    "\n",
    "- **動作確認済の環境**：16.3 ML Runtime\n",
    "- **推奨インスタンス**：AWS の `i3.xlarge` または Azure の `Standard_D4DS_v5`  \n",
    "- **Unity Catalog**：ワークスペースでUnity Catalogが有効化されていること\n",
    "- **GPU Model Serving**：GPUモデルサービングへのアクセス権限があること\n",
    "- **必要な権限**：\n",
    "  - Unity Catalogでのカタログ・スキーマ作成権限\n",
    "  - モデル登録・サービングエンドポイント作成権限\n",
    "\n",
    "--- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "975b470a-d7cc-4d30-8d93-c62ab4a6c35c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# カタログ、スキーマ、モデル名の定義\n",
    "# TODO: \n",
    "model_uc_catalog = \"skato\"\n",
    "model_uc_schema = \"models\"\n",
    "uc_model_name = \"plamo_embedding_1b\"\n",
    "\n",
    "# サービングエンドポイントの名前を指定\n",
    "serving_endpoint_name = 'skato-plamo-embedding'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8920d512-b5a6-4c37-b2a3-cef8a8d55fba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. パラメータの設定\n",
    "\n",
    "日本語埋め込みモデルのデプロイに必要なパラメータを設定します。\n",
    "\n",
    "### Unity Catalogの設定について\n",
    "- **カタログ**: Unity Catalogの最上位レベルのコンテナ\n",
    "- **スキーマ**: カタログ内のモデル管理用スキーマ  \n",
    "- **モデル名**: Unity Catalogでの登録モデル名\n",
    "\n",
    "### サービングエンドポイントについて\n",
    "GPU Model Servingを使用して、リアルタイムでの埋め込み生成APIを提供します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d82f6a1-e8d7-4f00-8770-cbcab83aa5d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# You can download models from the Hugging Face Hub 🤗 as follows:\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"pfnet/plamo-embedding-1b\", trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(\"pfnet/plamo-embedding-1b\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f9f2db2-a4c2-4902-8760-c25cd89ec4a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. モデルの取得とローカルテスト\n",
    "\n",
    "### Hugging Face Hubからのモデル取得\n",
    "\n",
    "PLaMo-Embedding-1Bは、Preferred Networks社が開発した日本語特化の埋め込みモデルです。Hugging Face Transformersライブラリを使用してモデルとトークナイザーを取得し、ローカルでの動作を確認します。\n",
    "\n",
    "### モデルの特徴\n",
    "- **言語特化**: 日本語テキストに最適化された埋め込み生成\n",
    "- **用途別メソッド**: `encode_query`（クエリ用）と`encode_document`（文書用）の使い分け\n",
    "- **高精度**: 日本語の情報検索タスクで高い性能を発揮"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "query = \"PLaMo-Embedding-1Bとは何ですか？\"\n",
    "documents = [\n",
    "    \"PLaMo-Embedding-1Bは、Preferred Networks, Inc. によって開発された日本語テキスト埋め込みモデルです。\",\n",
    "    \"最近は随分と暖かくなりましたね。\"\n",
    "]\n",
    "\n",
    "with torch.inference_mode():\n",
    "    # クエリテキストの埋め込み生成には `encode_query` メソッドを使用します。\n",
    "    # `tokenizer` も一緒に渡す必要があります。\n",
    "    query_embedding = model.encode_query(query, tokenizer)\n",
    "    # 他のテキストや文の場合は `encode_document` メソッドを使用してください。\n",
    "    # また、情報検索以外の用途でも `encode_document` メソッドを使用してください。\n",
    "    document_embeddings = model.encode_document(documents, tokenizer)\n",
    "\n",
    "\n",
    "similarities = F.cosine_similarity(query_embedding, document_embeddings)\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. モデルのMLflow登録\n",
    "\n",
    "### MLflow Transformersフレーバーについて\n",
    "\n",
    "MLflowのTransformersフレーバーを使用して、Hugging Faceモデルを企業レベルのモデル管理システムに統合します。\n",
    "\n",
    "**登録のメリット:**\n",
    "- **バージョン管理**: モデルの変更履歴とメタデータの追跡\n",
    "- **再現性**: モデルの再利用と一貫性の確保  \n",
    "- **ガバナンス**: Unity Catalogによるアクセス制御と監査\n",
    "- **デプロイメント**: サービングエンドポイントへの直接デプロイ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40966f59-b2ab-4509-ba30-db7e82848621",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "\n",
    "transformers_model = {\"model\": model, \"tokenizer\": tokenizer}\n",
    "task = \"llm/v1/embeddings\"  # 埋め込み用の正しいタスク\n",
    "\n",
    "# レジストリURIをUnity Catalogに設定\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# パイプラインを作成\n",
    "embedding_pipeline = pipeline(task=\"feature-extraction\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# モデルを登録\n",
    "with mlflow.start_run():\n",
    "    model_info = mlflow.transformers.log_model(\n",
    "        transformers_model=embedding_pipeline,\n",
    "        task=task,\n",
    "        artifact_path=\"model\",\n",
    "        registered_model_name=f\"{model_uc_catalog}.{model_uc_schema}.{uc_model_name}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "848a6c12-8114-4abf-90ea-068e2d02956c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4. Unity Catalogからのモデル読み込み\n",
    "\n",
    "### モデルエイリアス機能\n",
    "\n",
    "Unity Catalogでは、モデルバージョンにエイリアス（別名）を設定できます。これにより、常に最新バージョンや特定の環境用バージョンを参照できます。\n",
    "\n",
    "**エイリアスの利点:**\n",
    "- **バージョン抽象化**: 具体的なバージョン番号を意識せずにモデル参照\n",
    "- **環境管理**: development、staging、productionなどの環境別管理\n",
    "- **自動更新**: 新しいバージョンのデプロイ時の自動切り替え\n",
    "\n",
    "### MLflow Clientによる管理\n",
    "MLflow Clientを使用して、プログラムでモデルバージョンとエイリアスを管理できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1d7eb29-4ce1-45ff-bd52-616ba8dadf18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "# モデル名とエイリアスを定義\n",
    "registered_name = f\"{model_uc_catalog}.{model_uc_schema}.{uc_model_name}\"\n",
    "alias = \"latest_alias\"\n",
    "\n",
    "# 最新バージョンにエイリアスを設定\n",
    "client = MlflowClient()\n",
    "latest_version = max([int(m.version) for m in client.search_model_versions(f\"name='{registered_name}'\")])\n",
    "client.set_registered_model_alias(registered_name, alias, latest_version)\n",
    "\n",
    "# エイリアスを使用してモデルを読み込み\n",
    "loaded_model = mlflow.pyfunc.load_model(f\"models:/{registered_name}@{alias}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab63a121-7ff0-48ab-942d-943995cb5a12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 5. モデルサービングエンドポイントの作成\n",
    "\n",
    "### Model Servingについて\n",
    "\n",
    "Model Servingは、GPUアクセラレーションを活用した高性能なモデル推論サービスです。埋め込みモデルのような計算集約的なタスクに最適です。\n",
    "\n",
    "**主な特徴:**\n",
    "- **高速推論**: GPUによる並列処理で高速な埋め込み生成\n",
    "- **自動スケーリング**: トラフィックに応じた動的リソース調整\n",
    "- **Zero-downtime**: リクエストがない時間帯の自動スケールダウン\n",
    "- **API統合**: 標準的なREST APIでの簡単なアクセス\n",
    "\n",
    "### Databricks SDKによるプログラム制御\n",
    "\n",
    "Databricks SDKを使用することで、UIを使わずにプログラムでエンドポイントの作成・管理が可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0fd16e68-08a3-4c5b-aaf4-a093e18d198a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "databricks_url = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiUrl().getOrElse(None)\n",
    "token = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().getOrElse(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ec20b83-32ef-483b-9bb5-ea76022e93b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# サービングエンドポイントの作成または更新\n",
    "from datetime import timedelta\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.serving import EndpointCoreConfigInput, ServedModelInput, ServedModelInputWorkloadSize, ServedModelInputWorkloadType\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "# エイリアスを使用してモデルを読み込み\n",
    "model_uri = f\"models:/{registered_name}@{alias}\"\n",
    "model_name = registered_name\n",
    "\n",
    "# MLflowクライアントで最新モデルバージョンを取得する必要はありません\n",
    "# latest_model_version = client.get_latest_versions(model_name, stages=[\"None\"])[0].version\n",
    "\n",
    "w = WorkspaceClient()\n",
    "endpoint_config = EndpointCoreConfigInput(\n",
    "    name=serving_endpoint_name,\n",
    "    served_models=[\n",
    "        ServedModelInput(\n",
    "            model_name=model_name,\n",
    "            model_version=latest_version,  # Use the version directly\n",
    "            workload_type=ServedModelInputWorkloadType.GPU_SMALL,\n",
    "            workload_size=ServedModelInputWorkloadSize.SMALL,\n",
    "            scale_to_zero_enabled=True\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "existing_endpoint = next(\n",
    "    (e for e in w.serving_endpoints.list() if e.name == serving_endpoint_name), None\n",
    ")\n",
    "serving_endpoint_url = f\"{databricks_url}/ml/endpoints/{serving_endpoint_name}\"\n",
    "if existing_endpoint is None:\n",
    "    print(f\"Creating the endpoint {serving_endpoint_url}, this will take a few minutes to package and deploy the endpoint...\")\n",
    "    w.serving_endpoints.create_and_wait(name=serving_endpoint_name, config=endpoint_config, timeout=timedelta(minutes=60))\n",
    "else:\n",
    "    print(f\"Updating the endpoint {serving_endpoint_url} to version {version}, this will take a few minutes to package and deploy the endpoint...\")\n",
    "    w.serving_endpoints.update_config_and_wait(served_models=endpoint_config.served_models, name=serving_endpoint_name, timeout=timedelta(minutes=60))\n",
    "    \n",
    "displayHTML(f'Your Model Endpoint Serving is now available. Open the <a href=\"/ml/endpoints/{serving_endpoint_name}\">Model Serving Endpoint page</a> for more details.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b38c9d6-f8ed-45ce-b66f-d3e55838300c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### エンドポイントの準備確認\n",
    "\n",
    "モデルサービングエンドポイントのデプロイが完了し、`Ready`状態になったら、以下のテストを実行します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 6. サービングエンドポイントのテスト\n",
    "\n",
    "### MLflow Deployments SDKによるクエリ\n",
    "\n",
    "モデルサービングエンドポイントが準備完了したら、MLflow Deployments SDKを使用して簡単にテストできます。\n",
    "\n",
    "**テストのポイント:**\n",
    "- **入力形式**: 埋め込み生成したいテキストの配列\n",
    "- **出力形式**: 数値ベクトルとしての埋め込み表現\n",
    "- **パフォーマンス**: レスポンス時間と精度の確認\n",
    "\n",
    "### 本番利用への準備\n",
    "このテストが成功すれば、エンドポイントは本番のRAGアプリケーションで利用可能です。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7a15cd3-f277-4cf7-9957-63e67a409838",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow.deployments\n",
    "\n",
    "client = mlflow.deployments.get_deploy_client(\"databricks\")\n",
    "\n",
    "embeddings_response = client.predict(\n",
    "    endpoint=serving_endpoint_name,\n",
    "    inputs={\n",
    "        \"inputs\": [\"おはようございます\"]\n",
    "    }\n",
    ")\n",
    "embeddings_response['predictions']"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2400833312658622,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "参考_日本語埋め込みモデルのデプロイ",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
