{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "697a03ae-d416-4609-9a17-62200d647c8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Databricks RAGアプリチュートリアル - 2. RAGエージェントの構築\n",
    "\n",
    "このノートブックでは、前回のワークショップで作成したVector Search Indexを活用して、より高度なTool-calling RAG（Retrieval-Augmented Generation）エージェントを構築します。\n",
    "\n",
    "## このノートブックで学習する内容\n",
    "1. **Mosaic AI Agent Framework**の詳細理解\n",
    "2. **LangGraph**を使用した高度なエージェント実装\n",
    "3. **Tool-calling機能**によるマルチステップ推論\n",
    "4. **MLflow ChatAgent**インターフェースの活用\n",
    "5. **Unity Catalog統合**による企業レベルのガバナンス\n",
    "6. **デプロイとモニタリング**のベストプラクティス\n",
    "\n",
    "## 実行環境\n",
    "このノートブックはサーバーレスコンピュートでの実行を想定しています。\n",
    "\n",
    "## 前提条件\n",
    "- 1_workshop_vector_search.ipynbでVector Search Indexが作成済みであること\n",
    "- 必要なエンドポイントへのアクセス権限があること\n",
    "\n",
    "---\n",
    "\n",
    "## LangGraphとTool-calling Agentについて\n",
    "\n",
    "### LangGraphとは\n",
    "LangGraphは、LangChainエコシステムの一部として開発された、複雑なマルチエージェントワークフローを構築するためのライブラリです。\n",
    "\n",
    "**主な特徴:**\n",
    "- **State Management**: 複雑な状態管理\n",
    "- **Conditional Logic**: 条件分岐による動的フロー制御\n",
    "- **Tool Integration**: 外部ツールとのシームレスな統合\n",
    "- **Human-in-the-loop**: 人間の介入ポイントの設定\n",
    "\n",
    "### Tool-calling Agentの利点\n",
    "1. **マルチステップ推論**: 複数のツールを組み合わせた複雑なタスクの実行\n",
    "2. **動的ツール選択**: 文脈に応じた最適なツールの自動選択\n",
    "3. **エラー処理**: ツール実行失敗時の自動回復\n",
    "4. **拡張性**: 新しいツールの簡単な追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3548701b-b92b-43a4-9902-f198e4288301",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 必要なライブラリのインストール\n",
    "# MLflow 3.0以降とLangGraphを使用した高度なエージェント開発環境をセットアップ\n",
    "%pip install -U -qqqq mlflow-skinny[databricks] langgraph==0.3.4 databricks-langchain databricks-agents uv\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fab45e5e-ce43-46ca-b8c6-3c9907413ebb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3-1. エージェントの実装\n",
    "\n",
    "### Mosaic AI Agent Frameworkの詳細\n",
    "\n",
    "Mosaic AI Agent Frameworkは、Enterprise-gradeのRAGアプリケーション開発のために設計された包括的なソリューションです。\n",
    "\n",
    "**フレームワークの核心要素:**\n",
    "1. **ChatAgent Interface**: 標準化されたマルチターン会話インターフェース\n",
    "2. **Tool Integration**: 外部システムとの統合機能\n",
    "3. **State Management**: 会話状態の永続化\n",
    "4. **Security & Governance**: Unity Catalogによるアクセス制御\n",
    "\n",
    "### LangGraphによるワークフロー設計\n",
    "\n",
    "以下でエージェントコードを単一のセルで定義し、`%%writefile`マジックコマンドを使用してローカルPythonファイルに出力します。これにより、後続のロギングとデプロイメントが容易になります。\n",
    "\n",
    "**実装するエージェントアーキテクチャ:**\n",
    "- **Entry Point**: ユーザーからの質問受付\n",
    "- **Tool Selection**: 適切なツールの動的選択\n",
    "- **Conditional Edges**: 結果に基づく分岐処理\n",
    "- **Response Generation**: 最終回答の生成\n",
    "\n",
    "より多くのツールの例については、[公式ドキュメント](https://learn.microsoft.com/azure/databricks/generative-ai/agent-framework/agent-tool)をご参照ください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f107562-6c91-4c64-816e-9f7a5ca52997",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile agent.py\n",
    "\"\"\"\n",
    "Databricks Tool-calling RAG Agent Implementation\n",
    "\n",
    "このファイルは、LangGraphとMosaic AI Agent Frameworkを使用した\n",
    "高度なTool-calling RAGエージェントの実装です。\n",
    "\n",
    "主な機能:\n",
    "- Vector Searchを活用した文書検索\n",
    "- Unity Catalog Functionとの統合\n",
    "- マルチターン会話の管理\n",
    "- ストリーミング対応\n",
    "\"\"\"\n",
    "\n",
    "from typing import Any, Generator, Optional, Sequence, Union\n",
    "\n",
    "import mlflow\n",
    "from databricks_langchain import (\n",
    "    ChatDatabricks,\n",
    "    VectorSearchRetrieverTool,\n",
    "    DatabricksFunctionClient,\n",
    "    UCFunctionToolkit,\n",
    "    set_uc_function_client,\n",
    ")\n",
    "from langchain_core.language_models import LanguageModelLike\n",
    "from langchain_core.runnables import RunnableConfig, RunnableLambda\n",
    "from langchain_core.tools import BaseTool\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.graph.graph import CompiledGraph\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from langgraph.prebuilt.tool_node import ToolNode\n",
    "from mlflow.langchain.chat_agent_langgraph import ChatAgentState, ChatAgentToolNode\n",
    "from mlflow.pyfunc import ChatAgent\n",
    "from mlflow.types.agent import (\n",
    "    ChatAgentChunk,\n",
    "    ChatAgentMessage,\n",
    "    ChatAgentResponse,\n",
    "    ChatContext,\n",
    ")\n",
    "\n",
    "# MLflowの自動ログ機能を有効化\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "# Unity Catalog Function用のクライアント設定\n",
    "client = DatabricksFunctionClient()\n",
    "set_uc_function_client(client)\n",
    "\n",
    "############################################\n",
    "# LLMエンドポイントとシステムプロンプトの定義\n",
    "############################################\n",
    "LLM_ENDPOINT_NAME = \"databricks-claude-sonnet-4\"\n",
    "llm = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME)\n",
    "\n",
    "# システムプロンプト: エージェントの基本的な動作を定義\n",
    "system_prompt = \"\"\"あなたは生成AI開発に関する専門的なアシスタントです。\n",
    "登録されたVector Search Indexを活用して、\n",
    "ユーザーの質問に対して正確で有用な回答を提供してください。\n",
    "\n",
    "以下のガイドラインに従ってください：\n",
    "1. 利用可能なツールを効果的に活用してください\n",
    "2. 検索された文書の内容に基づいて回答してください  \n",
    "3. 不確かな情報については推測を避けてください\n",
    "4. 具体的で実用的なアドバイスを提供してください\n",
    "5. 日本語で丁寧に回答してください\n",
    "\n",
    "必要に応じて複数のツールを組み合わせて使用し、\n",
    "ユーザーにとって最も有益な情報を提供してください。\"\"\"\n",
    "\n",
    "###############################################################################\n",
    "## エージェントツールの定義\n",
    "## テキスト生成以外のデータ取得やアクション実行を可能にするツール群\n",
    "## 詳細な例については以下のドキュメントを参照:\n",
    "## https://learn.microsoft.com/azure/databricks/generative-ai/agent-framework/agent-tool\n",
    "###############################################################################\n",
    "tools = []\n",
    "\n",
    "# Unity CatalogのUDFをエージェントツールとして使用\n",
    "# 必要に応じて関数名を追加してください\n",
    "uc_tool_names = []\n",
    "uc_toolkit = UCFunctionToolkit(function_names=uc_tool_names)\n",
    "tools.extend(uc_toolkit.tools)\n",
    "\n",
    "# Vector Search Indexごとにretrieverツールを作成\n",
    "# 詳細: https://learn.microsoft.com/azure/databricks/generative-ai/agent-framework/unstructured-retrieval-tools\n",
    "vector_search_index_tools = [\n",
    "    VectorSearchRetrieverTool(\n",
    "        index_name=\"skato.rag_workshop.chunked_document_vs_index\",\n",
    "        tool_description=\"生成AI開発に関する技術文書やベストプラクティスを検索するためのツールです。GenAI開発ワークフロー、MLOps、エージェント設計などについて質問がある場合に使用してください。\"\n",
    "    )\n",
    "]\n",
    "tools.extend(vector_search_index_tools)\n",
    "\n",
    "#####################\n",
    "## エージェントロジックの定義\n",
    "#####################\n",
    "\n",
    "def create_tool_calling_agent(\n",
    "    model: LanguageModelLike,\n",
    "    tools: Union[Sequence[BaseTool], ToolNode],\n",
    "    system_prompt: Optional[str] = None,\n",
    ") -> CompiledGraph:\n",
    "    \"\"\"\n",
    "    Tool-calling機能を持つエージェントを作成\n",
    "    \n",
    "    Args:\n",
    "        model: 使用するLLMモデル\n",
    "        tools: エージェントが使用可能なツールのリスト\n",
    "        system_prompt: システムプロンプト\n",
    "    \n",
    "    Returns:\n",
    "        コンパイル済みのLangGraphワークフロー\n",
    "    \"\"\"\n",
    "    # モデルにツールをバインド\n",
    "    model = model.bind_tools(tools)\n",
    "\n",
    "    # 次のノードを決定する関数\n",
    "    def should_continue(state: ChatAgentState):\n",
    "        \"\"\"\n",
    "        エージェントがツールを呼び出すかどうかを判定\n",
    "        \"\"\"\n",
    "        messages = state[\"messages\"]\n",
    "        last_message = messages[-1]\n",
    "        # Function callがある場合は継続、そうでなければ終了\n",
    "        if last_message.get(\"tool_calls\"):\n",
    "            return \"continue\"\n",
    "        else:\n",
    "            return \"end\"\n",
    "\n",
    "    # システムプロンプトの前処理\n",
    "    if system_prompt:\n",
    "        preprocessor = RunnableLambda(\n",
    "            lambda state: [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "            + state[\"messages\"]\n",
    "        )\n",
    "    else:\n",
    "        preprocessor = RunnableLambda(lambda state: state[\"messages\"])\n",
    "    \n",
    "    model_runnable = preprocessor | model\n",
    "\n",
    "    def call_model(\n",
    "        state: ChatAgentState,\n",
    "        config: RunnableConfig,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        LLMモデルを呼び出し、レスポンスを処理\n",
    "        \"\"\"\n",
    "        response = model_runnable.invoke(state, config)\n",
    "        return {\"messages\": [response]}\n",
    "\n",
    "    # LangGraphワークフローの構築\n",
    "    workflow = StateGraph(ChatAgentState)\n",
    "\n",
    "    # ノードの追加\n",
    "    workflow.add_node(\"agent\", RunnableLambda(call_model))\n",
    "    workflow.add_node(\"tools\", ChatAgentToolNode(tools))\n",
    "\n",
    "    # エントリーポイントの設定\n",
    "    workflow.set_entry_point(\"agent\")\n",
    "    \n",
    "    # 条件分岐エッジの追加\n",
    "    workflow.add_conditional_edges(\n",
    "        \"agent\",\n",
    "        should_continue,\n",
    "        {\n",
    "            \"continue\": \"tools\",  # ツール実行へ\n",
    "            \"end\": END,          # 処理終了\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    # ツールからエージェントへのエッジ\n",
    "    workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "    return workflow.compile()\n",
    "\n",
    "\n",
    "class LangGraphChatAgent(ChatAgent):\n",
    "    \"\"\"\n",
    "    MLflow ChatAgentインターフェースを実装したLangGraphエージェント\n",
    "    \n",
    "    マルチターン会話とストリーミング対応を提供\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, agent: CompiledStateGraph):\n",
    "        self.agent = agent\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        messages: list[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[dict[str, Any]] = None,\n",
    "    ) -> ChatAgentResponse:\n",
    "        \"\"\"\n",
    "        同期的な予測処理\n",
    "        \n",
    "        Args:\n",
    "            messages: 会話履歴\n",
    "            context: 追加のコンテキスト情報\n",
    "            custom_inputs: カスタム入力パラメータ\n",
    "            \n",
    "        Returns:\n",
    "            ChatAgentResponse: エージェントの応答\n",
    "        \"\"\"\n",
    "        request = {\"messages\": self._convert_messages_to_dict(messages)}\n",
    "\n",
    "        messages = []\n",
    "        # ワークフローを実行し、すべての更新を収集\n",
    "        for event in self.agent.stream(request, stream_mode=\"updates\"):\n",
    "            for node_data in event.values():\n",
    "                messages.extend(\n",
    "                    ChatAgentMessage(**msg) for msg in node_data.get(\"messages\", [])\n",
    "                )\n",
    "        return ChatAgentResponse(messages=messages)\n",
    "\n",
    "    def predict_stream(\n",
    "        self,\n",
    "        messages: list[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[dict[str, Any]] = None,\n",
    "    ) -> Generator[ChatAgentChunk, None, None]:\n",
    "        \"\"\"\n",
    "        ストリーミング予測処理\n",
    "        \n",
    "        Args:\n",
    "            messages: 会話履歴\n",
    "            context: 追加のコンテキスト情報\n",
    "            custom_inputs: カスタム入力パラメータ\n",
    "            \n",
    "        Yields:\n",
    "            ChatAgentChunk: エージェントの応答チャンク\n",
    "        \"\"\"\n",
    "        request = {\"messages\": self._convert_messages_to_dict(messages)}\n",
    "        # ワークフローをストリーミング実行\n",
    "        for event in self.agent.stream(request, stream_mode=\"updates\"):\n",
    "            for node_data in event.values():\n",
    "                yield from (\n",
    "                    ChatAgentChunk(**{\"delta\": msg}) for msg in node_data[\"messages\"]\n",
    "                )\n",
    "\n",
    "\n",
    "# エージェントオブジェクトの作成\n",
    "# MLflow推論時に使用するエージェントとして設定\n",
    "agent = create_tool_calling_agent(llm, tools, system_prompt)\n",
    "AGENT = LangGraphChatAgent(agent)\n",
    "mlflow.models.set_model(AGENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2eabacb3-c0ac-4f9c-979e-7625e8af3ef6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3-2. エージェントのテスト\n",
    "\n",
    "### MLflow Tracingについて\n",
    "\n",
    "このノートブックでは`mlflow.langchain.autolog()`を呼び出しているため、エージェントが実行する各ステップのトレースをMLflow UIで確認することができます。\n",
    "\n",
    "**Tracingの利点:**\n",
    "1. **デバッグ支援**: 各ツール呼び出しの詳細な追跡\n",
    "2. **パフォーマンス分析**: レスポンス時間とボトルネックの特定\n",
    "3. **品質監視**: 入力・出力の品質管理\n",
    "4. **運用監視**: プロダクション環境でのエージェント動作監視\n",
    "\n",
    "### インタラクティブテスト\n",
    "\n",
    "エージェントとの対話を通じて出力をテストします。以下のプレースホルダー入力を、あなたのエージェントに適した具体的な例に置き換えてください。\n",
    "\n",
    "**テスト観点:**\n",
    "- Vector Searchによる関連文書の検索精度\n",
    "- LLMによる回答生成の品質\n",
    "- Tool-calling機能の適切な動作\n",
    "- マルチステップ推論の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41b6ab1c-159f-4d6d-a619-8a7005b6c37a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Pythonライブラリの再起動\n",
    "# agent.pyファイルの変更を反映するため\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d08f7a6-a840-4149-86d9-a36d72a59f47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# エージェントのインポートとBasic Test\n",
    "from agent import AGENT\n",
    "\n",
    "# 基本的な動作テスト\n",
    "print(\"=== 基本動作テスト ===\")\n",
    "response = AGENT.predict({\"messages\": [{\"role\": \"user\", \"content\": \"Hello!\"}]})\n",
    "print(\"エージェントからの応答:\")\n",
    "for message in response.messages:\n",
    "    print(f\"Role: {message.role}\")\n",
    "    print(f\"Content: {message.content}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4639baf6-30b5-40a5-874f-51d9d450af4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ストリーミング機能のテスト\n",
    "print(\"=== ストリーミングテスト ===\")\n",
    "print(\"質問: 生成AIの開発ワークフローについて教えてください\")\n",
    "print(\"\\n--- ストリーミング応答 ---\")\n",
    "\n",
    "for event in AGENT.predict_stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"生成AIの開発ワークフローについて教えてください\"}]}\n",
    "):\n",
    "    if hasattr(event, 'delta') and event.delta:\n",
    "        if hasattr(event.delta, 'content') and event.delta.content:\n",
    "            print(event.delta.content, end=\"\", flush=True)\n",
    "        elif hasattr(event.delta, 'tool_calls') and event.delta.tool_calls:\n",
    "            print(f\"\\n[ツール呼び出し: {event.delta.tool_calls}]\")\n",
    "    print() # 改行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b42116b-5578-45e6-ac27-66bc7d0cfa7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3-3. エージェントのMLflowモデルとしてのログ記録\n",
    "\n",
    "### リソース指定とセキュリティ\n",
    "\n",
    "デプロイメント時の自動認証パススルーのために必要なDatabricksリソースを特定します。\n",
    "\n",
    "**重要な考慮事項:**\n",
    "- **Vector Search Index**: Unity Catalog Functionがvector search indexにアクセスする場合、依存するインデックスをリソースとして含める必要があります\n",
    "- **External Functions**: 外部関数を活用する場合、UC接続オブジェクトをリソースとして含める必要があります\n",
    "- **自動認証**: 詳細については[公式ドキュメント](https://learn.microsoft.com/azure/databricks/generative-ai/agent-framework/log-agent#specify-resources-for-automatic-authentication-passthrough)を参照\n",
    "\n",
    "### Models from Code\n",
    "\n",
    "`agent.py`ファイルからエージェントをコードとしてログします。詳細は[MLflow - Models from Code](https://mlflow.org/docs/latest/models.html#models-from-code)を参照してください。\n",
    "\n",
    "**Benefits:**\n",
    "1. **バージョン管理**: コードの変更履歴の追跡\n",
    "2. **再現性**: 同じ環境での確実な再現\n",
    "3. **デプロイメント**: プロダクション環境への安全なデプロイ\n",
    "4. **依存関係管理**: 必要なライブラリの自動管理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf4eefcd-c2b2-426e-a50d-13babc0b1fcd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# デプロイメント時の自動認証パススルー用のDatabricksリソース特定\n",
    "import mlflow\n",
    "from agent import LLM_ENDPOINT_NAME, tools\n",
    "from databricks_langchain import VectorSearchRetrieverTool\n",
    "from mlflow.models.resources import DatabricksFunction, DatabricksServingEndpoint\n",
    "from pkg_resources import get_distribution\n",
    "from unitycatalog.ai.langchain.toolkit import UnityCatalogTool\n",
    "\n",
    "print(\"=== リソース設定 ===\")\n",
    "\n",
    "# LLMエンドポイントをリソースとして追加\n",
    "resources = [DatabricksServingEndpoint(endpoint_name=LLM_ENDPOINT_NAME)]\n",
    "print(f\"LLMエンドポイント: {LLM_ENDPOINT_NAME}\")\n",
    "\n",
    "# 各ツールの依存リソースを確認・追加\n",
    "for tool in tools:\n",
    "    if isinstance(tool, VectorSearchRetrieverTool):\n",
    "        print(f\"Vector Search Tool: {tool.index_name}\")\n",
    "        resources.extend(tool.resources)\n",
    "    elif isinstance(tool, UnityCatalogTool):\n",
    "        print(f\"Unity Catalog Tool: {tool.uc_function_name}\")\n",
    "        # TODO: UC functionが外部接続やvector searchに依存する場合は、\n",
    "        # それらのリソースを手動で追加する必要があります\n",
    "        resources.append(DatabricksFunction(function_name=tool.uc_function_name))\n",
    "\n",
    "print(f\"総リソース数: {len(resources)}\")\n",
    "\n",
    "# モデルの入力例を定義\n",
    "input_example = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"LLMエージェントとは何ですか？\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"\\n=== MLflowモデルログ記録 ===\")\n",
    "\n",
    "# MLflow実行の開始とモデルログ\n",
    "with mlflow.start_run():\n",
    "    # パフォーマンス情報の記録\n",
    "    mlflow.log_param(\"llm_endpoint\", LLM_ENDPOINT_NAME)\n",
    "    mlflow.log_param(\"num_tools\", len(tools))\n",
    "    mlflow.log_param(\"framework\", \"LangGraph\")\n",
    "    \n",
    "    # モデルのログ記録\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        name=\"agent\",\n",
    "        python_model=\"agent.py\",\n",
    "        input_example=input_example,\n",
    "        resources=resources,\n",
    "        pip_requirements=[\n",
    "            f\"databricks-connect=={get_distribution('databricks-connect').version}\",\n",
    "            f\"mlflow=={get_distribution('mlflow').version}\",\n",
    "            f\"databricks-langchain=={get_distribution('databricks-langchain').version}\",\n",
    "            f\"langgraph=={get_distribution('langgraph').version}\",\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    print(f\"モデルがログされました: {logged_agent_info.model_uri}\")\n",
    "    print(f\"Run ID: {logged_agent_info.run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5c70b76-e0f4-469d-b08f-dd93d593ffe8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3-4. Agent Evaluationによるエージェント評価\n",
    "\n",
    "### MLflow 3.0 Agent Evaluationについて\n",
    "\n",
    "[Agent Evaluation](https://learn.microsoft.com/azure/databricks/mlflow3/genai/eval-monitor/)は、生成AIエージェントの品質を定量的に評価するための強力なフレームワークです。\n",
    "\n",
    "**主な特徴:**\n",
    "- **LLM-as-a-Judge**: 他のLLMモデルを評価者として活用\n",
    "- **事前定義メトリクス**: 標準的な品質指標\n",
    "- **カスタムメトリクス**: ドメイン特有の評価基準\n",
    "- **継続的監視**: プロダクション環境でのリアルタイム監視\n",
    "\n",
    "### 評価のワークフロー\n",
    "\n",
    "1. **評価データセット作成**: 期待される応答と共にテストケースを定義\n",
    "2. **メトリクス選択**: 適切な評価指標の選択\n",
    "3. **評価実行**: エージェントのパフォーマンス測定\n",
    "4. **結果分析**: MLflowでの品質メトリクス追跡\n",
    "\n",
    "評価データセットの質問や期待される応答を編集し、エージェントの改善に合わせて評価を実行できます。MLflowを活用して計算された品質メトリクスを追跡することが可能です。\n",
    "\n",
    "[事前定義されたLLMスコアラー](https://learn.microsoft.com/azure/databricks/mlflow3/genai/eval-monitor/predefined-judge-scorers)でエージェントを評価するか、[カスタムメトリクス](https://learn.microsoft.com/azure/databricks/mlflow3/genai/eval-monitor/custom-scorers)の追加をお試しください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2a09b94-c4c3-4849-a62f-40f27474938e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# MLflow Agent Evaluationの実行\n",
    "import mlflow\n",
    "from mlflow.genai.scorers import RelevanceToQuery, Safety, RetrievalRelevance, RetrievalGroundedness\n",
    "\n",
    "print(\"=== Agent Evaluation実行 ===\")\n",
    "\n",
    "# 評価データセットの定義\n",
    "# 実際の使用ケースに応じてデータセットを拡張してください\n",
    "eval_dataset = [\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"生成AIの開発ワークフローについて詳しく教えてください\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \"expected_response\": None  # 期待される応答がある場合はここに記載\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": \"MLOpsのベストプラクティスは何ですか？\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \"expected_response\": None\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"Vector SearchとRAGの関係について説明してください\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \"expected_response\": None\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"評価データセット: {len(eval_dataset)} 件のテストケース\")\n",
    "\n",
    "# エージェント評価の実行\n",
    "# 使用可能なスコアラー:\n",
    "# - RelevanceToQuery: 質問に対する回答の関連性\n",
    "# - Safety: 安全性（有害性の検出）\n",
    "# - RetrievalRelevance: 検索された文書の関連性\n",
    "# - RetrievalGroundedness: 文書に基づいた回答かどうか\n",
    "eval_results = mlflow.genai.evaluate(\n",
    "    data=eval_dataset,\n",
    "    predict_fn=lambda messages: AGENT.predict({\"messages\": messages}),\n",
    "    scorers=[\n",
    "        RelevanceToQuery(),  # 質問関連性\n",
    "        Safety(),           # 安全性\n",
    "        # 以下は必要に応じて追加\n",
    "        # RetrievalRelevance(),   # 検索関連性\n",
    "        # RetrievalGroundedness() # 文書根拠性\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"評価が完了しました！\")\n",
    "print(\"MLflow UIで詳細な評価結果を確認してください\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6440f4dc-f003-4004-b22a-92cc2fe0fece",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3-5. エージェントのデプロイ前検証\n",
    "\n",
    "### デプロイ前検証の重要性\n",
    "\n",
    "エージェントを登録・デプロイする前に、[mlflow.models.predict()](https://mlflow.org/docs/latest/python_api/mlflow.models.html#mlflow.models.predict) APIを通じて事前検証を実行します。\n",
    "\n",
    "**検証の目的:**\n",
    "1. **環境一貫性**: 開発環境とプロダクション環境の動作確認\n",
    "2. **依存関係チェック**: 必要なライブラリとリソースの確認\n",
    "3. **入力形式検証**: 期待される入力形式の確認\n",
    "4. **エラー処理**: 例外処理の動作確認\n",
    "\n",
    "**検証プロセス:**\n",
    "- ローカル環境でのモデル復元\n",
    "- テスト入力による動作確認\n",
    "- レスポンス形式の検証\n",
    "- パフォーマンス測定\n",
    "\n",
    "詳細については[公式ドキュメント](https://learn.microsoft.com/azure/databricks/machine-learning/model-serving/model-serving-debug#validate-inputs)を参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4c516b5-424f-4d06-bf84-e475a2e59fe6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.models.predict(\n",
    "    model_uri=f\"runs:/{logged_agent_info.run_id}/agent\",\n",
    "    input_data={\"messages\": [{\"role\": \"user\", \"content\": \"Hello!\"}]},\n",
    "    env_manager=\"virtualenv\",\n",
    ")\n",
    "\n",
    "# デプロイ前検証の実行\n",
    "# print(\"=== デプロイ前検証開始 ===\")\n",
    "\n",
    "# try:\n",
    "#     # テスト用入力データ\n",
    "#     test_input = {\n",
    "#         \"messages\": [\n",
    "#             {\n",
    "#                 \"role\": \"user\", \n",
    "#                 \"content\": \"生成AIエージェントの基本的な仕組みについて教えてください\"\n",
    "#             }\n",
    "#         ]\n",
    "#     }\n",
    "    \n",
    "#     print(\"テスト入力:\", test_input[\"messages\"][0][\"content\"])\n",
    "#     print(\"モデル復元中...\")\n",
    "    \n",
    "#     # MLflowモデルの予測実行\n",
    "#     # env_manager=\"uv\"を使用して依存関係を管理\n",
    "#     result = mlflow.models.predict(\n",
    "#         model_uri=f\"runs:/{logged_agent_info.run_id}/agent\",\n",
    "#         input_data=test_input,\n",
    "#         env_manager=\"uv\",\n",
    "#     )\n",
    "    \n",
    "#     print(\"✅ 検証成功!\")\n",
    "#     print(\"\\n--- 応答結果 ---\")\n",
    "#     if hasattr(result, 'messages'):\n",
    "#         for message in result.messages:\n",
    "#             print(f\"Role: {message.role}\")\n",
    "#             print(f\"Content: {message.content[:200]}...\")\n",
    "#             print(\"-\" * 30)\n",
    "#     else:\n",
    "#         print(\"Result:\", str(result)[:200])\n",
    "    \n",
    "# except Exception as e:\n",
    "#     print(f\"❌ 検証失敗: {str(e)}\")\n",
    "#     print(\"デプロイ前に問題を修正する必要があります\")\n",
    "\n",
    "# print(\"\\n=== 検証完了 ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d9f7b831-b44b-43b4-9d62-ea4a3f065fc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3-6. Unity Catalogへのモデル登録\n",
    "\n",
    "### Unity Catalogによるガバナンス\n",
    "\n",
    "Unity Catalogは、Databricksの統一ガバナンスソリューションです。MLflowモデルをUnity Catalogに登録することで、以下の利点が得られます。\n",
    "\n",
    "**主な利点:**\n",
    "1. **アクセス制御**: 細かい権限管理とセキュリティ\n",
    "2. **監査ログ**: 完全なアクセス履歴の追跡\n",
    "3. **メタデータ管理**: モデルの詳細情報とリネージ\n",
    "4. **バージョン管理**: モデルの変更履歴とロールバック機能\n",
    "5. **組織全体での共有**: チーム間でのモデル共有\n",
    "\n",
    "### 登録手順\n",
    "\n",
    "以下の`catalog`、`schema`、`model_name`を更新して、MLflowモデルをUnity Catalogに登録してください。\n",
    "\n",
    "**命名規則のベストプラクティス:**\n",
    "- **catalog**: 組織またはビジネスユニット名\n",
    "- **schema**: プロジェクトまたはドメイン名  \n",
    "- **model_name**: 機能を表す分かりやすい名前"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3f24c03-3cc1-472a-8150-3e7a1fd2c5d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Unity Catalogへのモデル登録\n",
    "print(\"=== Unity Catalog登録 ===\")\n",
    "\n",
    "# Unity CatalogをMLflowレジストリとして設定\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# Unity Catalogモデルの定義\n",
    "# 実際の環境に合わせて更新してください\n",
    "catalog = \"skato\"  # あなたのカタログ名\n",
    "schema = \"rag_workshop\"  # スキーマ名\n",
    "model_name = \"tool_calling_rag_agent\"  # モデル名\n",
    "\n",
    "UC_MODEL_NAME = f\"{catalog}.{schema}.{model_name}\"\n",
    "\n",
    "print(f\"登録先: {UC_MODEL_NAME}\")\n",
    "\n",
    "try:\n",
    "    # Unity Catalogにモデルを登録\n",
    "    uc_registered_model_info = mlflow.register_model(\n",
    "        model_uri=logged_agent_info.model_uri, \n",
    "        name=UC_MODEL_NAME\n",
    "    )\n",
    "    \n",
    "    print(\"✅ Unity Catalogへの登録が完了しました!\")\n",
    "    print(f\"モデル名: {uc_registered_model_info.name}\")\n",
    "    print(f\"バージョン: {uc_registered_model_info.version}\")\n",
    "    print(f\"ステータス: {uc_registered_model_info.current_stage}\")\n",
    "    \n",
    "    # メタデータの設定\n",
    "    mlflow.set_model_version_tag(\n",
    "        name=UC_MODEL_NAME,\n",
    "        version=uc_registered_model_info.version,\n",
    "        key=\"framework\",\n",
    "        value=\"LangGraph\"\n",
    "    )\n",
    "    \n",
    "    mlflow.set_model_version_tag(\n",
    "        name=UC_MODEL_NAME,\n",
    "        version=uc_registered_model_info.version,\n",
    "        key=\"use_case\",\n",
    "        value=\"RAG Tool-calling Agent\"\n",
    "    )\n",
    "    \n",
    "    print(\"メタデータタグが設定されました\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ 登録エラー: {str(e)}\")\n",
    "    print(\"カタログ、スキーマ、モデル名を確認してください\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "41478a55-dfbe-43d8-9dc9-62d0a9691947",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3-7. エージェントのデプロイメント\n",
    "\n",
    "### Model Servingについて\n",
    "\n",
    "Databricks Model Servingは、機械学習モデルをRESTful APIとして本番環境にデプロイするためのマネージドサービスです。\n",
    "\n",
    "**主な特徴:**\n",
    "1. **オートスケーリング**: トラフィックに応じた自動スケーリング\n",
    "2. **A/Bテスト**: 複数のモデルバージョンのトラフィック分割\n",
    "3. **モニタリング**: リアルタイムのパフォーマンス監視\n",
    "4. **セキュリティ**: 企業レベルのセキュリティとアクセス制御\n",
    "5. **高可用性**: フォルトトレラントなインフラストラクチャ\n",
    "\n",
    "### デプロイメントプロセス\n",
    "\n",
    "エージェントをサービングエンドポイントとしてデプロイし、REST APIを通じてアクセス可能にします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a483b9e-561f-41dd-9ad1-80a960be65e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# エージェントのデプロイメント\n",
    "print(\"=== エージェントデプロイメント ===\")\n",
    "\n",
    "from databricks import agents\n",
    "\n",
    "try:\n",
    "    # エージェントをModel Servingエンドポイントとしてデプロイ\n",
    "    deployment_info = agents.deploy(\n",
    "        UC_MODEL_NAME, \n",
    "        uc_registered_model_info.version, \n",
    "        tags={\n",
    "            \"endpointSource\": \"workshop\",\n",
    "            \"framework\": \"LangGraph\",\n",
    "            \"version\": \"v1.0\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(\"✅ デプロイメントが開始されました!\")\n",
    "    print(f\"エンドポイント名: {UC_MODEL_NAME.replace('.', '_')}\")\n",
    "    print(f\"モデルバージョン: {uc_registered_model_info.version}\")\n",
    "    \n",
    "    print(\"\\n--- デプロイメント情報 ---\")\n",
    "    print(\"デプロイメントの完了まで数分かかる場合があります\")\n",
    "    print(\"以下でエンドポイントの状態を確認できます:\")\n",
    "    print(\"1. Databricks UIのModel Servingセクション\")\n",
    "    print(\"2. AI Playground\")\n",
    "    print(\"3. REST API経由でのアクセス\")\n",
    "    \n",
    "    print(\"\\n--- 次のステップ ---\")\n",
    "    print(\"1. エンドポイントの準備完了を待つ\")\n",
    "    print(\"2. AI Playgroundでテスト\")\n",
    "    print(\"3. 本番アプリケーションとの統合\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ デプロイメントエラー: {str(e)}\")\n",
    "    print(\"Unity Catalogモデルの登録状況を確認してください\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "feec5389-d532-44c0-95cb-c7152b5b6714",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## まとめと次のステップ\n",
    "\n",
    "### ワークショップの完了\n",
    "\n",
    "🎉 **おめでとうございます！** Tool-calling RAGエージェントの開発・評価・デプロイが完了しました。\n",
    "\n",
    "### このノートブックで学習した内容\n",
    "\n",
    "1. **LangGraphによる高度なエージェント設計**\n",
    "   - 複雑なワークフローの実装\n",
    "   - 条件分岐とツール選択\n",
    "   - 状態管理とマルチステップ推論\n",
    "\n",
    "2. **Mosaic AI Agent Frameworkの活用**\n",
    "   - Unity Catalogとの統合\n",
    "   - セキュリティとガバナンス\n",
    "   - Enterprise-gradeの機能\n",
    "\n",
    "3. **MLflow 3.0による運用管理**\n",
    "   - モデルのログとバージョン管理\n",
    "   - 自動評価とモニタリング\n",
    "   - トレーシングとデバッグ\n",
    "\n",
    "4. **プロダクションデプロイメント**\n",
    "   - Model Servingによるスケーラブルなデプロイ\n",
    "   - REST API経由でのアクセス\n",
    "   - 継続的な運用監視\n",
    "\n",
    "### 次のステップ\n",
    "\n",
    "エージェントがデプロイされた後、以下の活動を通じてさらなる改善を図ることができます：\n",
    "\n",
    "#### 1. 品質向上\n",
    "- **AI Playground**でのインタラクティブテスト\n",
    "- 社内SME（Subject Matter Expert）からのフィードバック収集\n",
    "- 評価メトリクスの継続的監視\n",
    "\n",
    "#### 2. 本番統合\n",
    "- プロダクションアプリケーションへの組み込み\n",
    "- REST API経由での統合開発\n",
    "- ユーザーフィードバックの収集\n",
    "\n",
    "#### 3. スケーリング\n",
    "- **A/Bテスト**による機能改善\n",
    "- **多言語対応**の実装\n",
    "- **カスタムツール**の追加開発\n",
    "\n",
    "#### 4. 運用最適化\n",
    "- **パフォーマンス監視**の設定\n",
    "- **コスト最適化**の実施\n",
    "- **セキュリティ強化**の継続\n",
    "\n",
    "### 参考リンク\n",
    "\n",
    "- [Databricks エージェントデプロイメントガイド](https://learn.microsoft.com/azure/databricks/generative-ai/deploy-agent)\n",
    "- [AI Playground使用方法](https://learn.microsoft.com/azure/databricks/generative-ai/ai-playground)\n",
    "- [Model Serving運用ガイド](https://learn.microsoft.com/azure/databricks/machine-learning/model-serving/)\n",
    "- [Unity Catalogベストプラクティス](https://learn.microsoft.com/azure/databricks/data-governance/unity-catalog/)\n",
    "\n",
    "---\n",
    "\n",
    "**これでDatabricks RAGアプリケーション開発のワークショップシリーズが完了です。**\n",
    "**学習した技術を活用して、組織の生成AIプロジェクトを成功に導いてください！**"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "2_RAGエージェントの構築",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
